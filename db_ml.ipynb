{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./docs/Clean_Dataset.csv\")\n",
    "data = data[data.price <= 100000]\n",
    "train, test = train_test_split(data,test_size=0.30)\n",
    "train['price'] = train['price'].astype(float)\n",
    "test['price'] = test['price'].astype(float)\n",
    "\n",
    "train.to_csv(\"./docs/train.csv\",index=False)\n",
    "test.to_csv(\"./docs/test.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark = SparkSession.builder.appName(\"demo2\")\\\n",
    ".config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.3\") \\\n",
    ".config(\"spark.jars\", \"./jars/sqlite-jdbc-3.47.0.0.jar\")\\\n",
    ".config(\"spark.driver.extraClassPath\", \"./jars/sqlite-jdbc-3.47.0.0.jar\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(spark, filepath):    \n",
    "    data = spark.read.csv(filepath, header=True, inferSchema=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_cols=['airline',  'source_city', 'departure_time','stops', 'arrival_time',\n",
    "#             'destination_city', 'class', 'duration','days_left', ]\n",
    "# target_col='price'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class pre_process:\n",
    "    def __init__(self, train_data):\n",
    "        self.train_data = train_data\n",
    "        self.train_numerical_features = ['duration', 'days_left']\n",
    "        self.train_categorical_features = self.get_categorical_features()\n",
    "\n",
    "    def get_categorical_features(self):\n",
    "        pandas_df = self.train_data.toPandas()\n",
    "        categorical_features = pandas_df.select_dtypes(\n",
    "            include='object').columns.tolist()\n",
    "        return categorical_features\n",
    "\n",
    "    # Convert categorical features into nominal features\n",
    "\n",
    "    def get_indexers(self):\n",
    "        indexers = [StringIndexer(inputCol=feature, outputCol=feature + \"_index\",\n",
    "                                  handleInvalid='keep') for feature in self.train_categorical_features]\n",
    "        return indexers\n",
    "\n",
    "    # One hot encode categorical features\n",
    "    def get_encoders(self):\n",
    "        encoders = [OneHotEncoder(inputCols=[feature + \"_index\"], outputCols=[feature + \"_encoded\"],\n",
    "                                  handleInvalid='keep') for feature in self.train_categorical_features]\n",
    "        return encoders\n",
    "\n",
    "    # Scale numerical features\n",
    "    def get_numerical_f_assembler_scaler(self):\n",
    "        numerical_assembler = VectorAssembler(\n",
    "            inputCols=self.train_numerical_features, outputCol=\"numerical_features\")\n",
    "        scaler = MinMaxScaler(inputCol=\"numerical_features\",\n",
    "                              outputCol=\"numerical_features_scaled\")\n",
    "        return numerical_assembler, scaler\n",
    "\n",
    "    def get_pipeline_model(self):\n",
    "\n",
    "        indexers = self.get_indexers()\n",
    "        encoders = self.get_encoders()\n",
    "        numerical_assembler, scaler = self.get_numerical_f_assembler_scaler()\n",
    "        encoded_feature_cols = [\n",
    "            feature + \"_encoded\" for feature in self.train_categorical_features]\n",
    "        \n",
    "        final_assembler = VectorAssembler(\n",
    "            inputCols=encoded_feature_cols + [\"numerical_features_scaled\"],\n",
    "            outputCol=\"features\"\n",
    "        )\n",
    "\n",
    "\n",
    "        pipeline_indexers_encoders = Pipeline(\n",
    "            stages=indexers + encoders + [numerical_assembler, scaler, final_assembler])\n",
    "        pipeline_model = pipeline_indexers_encoders.fit(self.train_data)\n",
    "\n",
    "       \n",
    "\n",
    "        return pipeline_model\n",
    "\n",
    "    def save_fitted_pipeline_model(self, pipeline_model, path_string):\n",
    "        try:\n",
    "            pipeline_model.save(path_string)\n",
    "        except:\n",
    "            print(\"Error Saving Pipeline Model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_data(spark,\"./docs/train.csv\")\n",
    "pre_processor = pre_process(train_data)\n",
    "pipeline_model = pre_processor.get_pipeline_model()\n",
    "prepared_data = pipeline_model.transform(train_data)\n",
    "pre_processor.save_fitted_pipeline_model(pipeline_model, \"./docs/pipeline_model_backup\")\n",
    "random_forest = RandomForestRegressor(\n",
    "        featuresCol=\"features\", labelCol=\"price\")\n",
    "random_forest_model = random_forest.fit(prepared_data)\n",
    "random_forest_model.save(\"./docs/random_forest_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 0.9429297855648334\n",
      "RMSE: 5407.781430014901\n",
      "MAE: 3279.9095001396186\n",
      "+------------------+-------+\n",
      "|        prediction|  price|\n",
      "+------------------+-------+\n",
      "| 6985.515678828156| 4977.0|\n",
      "| 6197.119120766118| 4979.0|\n",
      "| 3478.984800043037| 3999.0|\n",
      "| 6197.119120766118| 8877.0|\n",
      "| 57178.71626939456|52175.0|\n",
      "|10543.504823219853|14094.0|\n",
      "|7058.3513565095345| 3988.0|\n",
      "| 4254.721948219717| 9736.0|\n",
      "|47122.152250934465|39321.0|\n",
      "| 4213.493524061561| 3393.0|\n",
      "| 6244.419227667903| 6699.0|\n",
      "| 4973.282581774701| 3788.0|\n",
      "|  7078.68589514644| 4230.0|\n",
      "| 5647.882162321157| 5289.0|\n",
      "|56264.148308125696|60365.0|\n",
      "| 5592.985464400039| 9136.0|\n",
      "| 5911.097051480472| 4363.0|\n",
      "| 7774.495685135902|16065.0|\n",
      "| 6184.719542630145| 6568.0|\n",
      "|3614.9918310625862| 2074.0|\n",
      "+------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = read_data(spark,\"./docs/test.csv\")\n",
    "\n",
    "\n",
    "prepared_data = pipeline_model.transform(\n",
    "    test_data).select(\"features\", \"price\")\n",
    "\n",
    "predictions = random_forest_model.transform(prepared_data)\n",
    "\n",
    "\n",
    "\n",
    "r2_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "rmse_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "mae_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "\n",
    "\n",
    "r2 = r2_evaluator.evaluate(predictions)\n",
    "rmse = rmse_evaluator.evaluate(predictions)\n",
    "mae = mae_evaluator.evaluate(predictions)\n",
    "\n",
    "\n",
    "print(\"R²:\", r2)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE:\", mae)\n",
    "predictions.select(\"prediction\", \"price\").show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
